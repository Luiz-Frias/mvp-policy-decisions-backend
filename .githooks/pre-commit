#!/bin/bash
# 🛡️ MASTER RULESET ENFORCEMENT - Pre-commit Validation Pipeline
# Enforces Defensive Programming & Performance First Principles

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m'

print_status() { echo -e "${BLUE}[INFO]${NC} $1"; }
print_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }
print_warning() { echo -e "${YELLOW}[WARNING]${NC} $1"; }
print_error() { echo -e "${RED}[ERROR]${NC} $1"; }
print_header() { echo -e "${PURPLE}$1${NC}"; }

print_header "🛡️ MASTER RULESET ENFORCEMENT - Pre-commit Validation"
print_status "Enforcing Defensive Programming & Performance First Principles..."

# ---------------------------------------------
# MASTER RULE: Pydantic / Defensive checks
# We want to collect *all* violations and then exit once, rather than aborting
# at the first failure.  Temporarily relax `set -e` and aggregate results.
# ---------------------------------------------

print_status "🔍 MASTER RULE: Validating Pydantic model compliance..."

# Disable immediate-exit so we can gather every issue.
set +e
VIOLATIONS=0

# 1️⃣  Plain dictionary usage that is not at a SYSTEM_BOUNDARY
DICT_VIOL_FILES=$(find src -name "*.py" -exec grep -l "dict\\[" {} \; 2>/dev/null | xargs grep -L "SYSTEM_BOUNDARY" 2>/dev/null)
if [ -n "$DICT_VIOL_FILES" ]; then
    COUNT=$(echo "$DICT_VIOL_FILES" | wc -l)
    print_error "❌ MASTER RULE VIOLATION: $COUNT file(s) use plain dictionaries without annotation:" 
    echo "$DICT_VIOL_FILES" | sed 's/^/   • /'
    VIOLATIONS=$((VIOLATIONS+COUNT))
fi

# 2️⃣  Pydantic models missing frozen=True
BASEMODEL_FILES=$(find src -name "*.py" -exec grep -l "class.*BaseModel" {} \; 2>/dev/null)
UNFROZEN_LIST=""
if [ -n "$BASEMODEL_FILES" ]; then
    UNFROZEN_LIST=$(echo "$BASEMODEL_FILES" | xargs grep -L "frozen.*=.*True" 2>/dev/null)
fi
if [ -n "$UNFROZEN_LIST" ]; then
    COUNT=$(echo "$UNFROZEN_LIST" | wc -l)
    print_error "❌ MASTER RULE VIOLATION: $COUNT model(s) lack frozen=True:" 
    echo "$UNFROZEN_LIST" | sed 's/^/   • /'
    VIOLATIONS=$((VIOLATIONS+COUNT))
fi

# 3️⃣  Public functions missing @beartype
PUBLIC_FUNCS_FILES=$(find src -name "*.py" -exec grep -l "^def [^_]" {} \; 2>/dev/null)
MISSING_BEAR=""
if [ -n "$PUBLIC_FUNCS_FILES" ]; then
    MISSING_BEAR=$(echo "$PUBLIC_FUNCS_FILES" | xargs grep -L "@beartype" 2>/dev/null)
fi
if [ -n "$MISSING_BEAR" ]; then
    COUNT=$(echo "$MISSING_BEAR" | wc -l)
    print_error "❌ MASTER RULE VIOLATION: $COUNT public function file(s) without @beartype:" 
    echo "$MISSING_BEAR" | sed 's/^/   • /'
    VIOLATIONS=$((VIOLATIONS+COUNT))
fi

# Re-enable strict mode for the remainder of the script.
set -e

# Final decision for this validation block
if [ "$VIOLATIONS" -gt 0 ]; then
    print_error "🚨 MASTER RULESET: Fix the violations above before committing"
    exit 1
else
    print_success "✅ Pydantic model compliance verified"
fi

# 2. MANDATORY: MyPy Strict Mode Enforcement
print_status "🔒 MASTER RULE: MyPy strict mode validation..."
if ! uv run mypy --strict src; then
    print_error "❌ MASTER RULE VIOLATION: MyPy strict mode failed"
    print_error "🚨 TYPE SAFETY: Code must pass mypy --strict without ignores"
    exit 1
fi
print_success "✅ MyPy strict mode validation passed"

# 3. MANDATORY: Performance Benchmark Validation
print_status "⚡ MASTER RULE: Performance benchmark validation..."
LONG_FUNCTIONS=$(find src -name "*.py" -exec grep -c "^def \|^    def " {} \; 2>/dev/null | \
    awk -F: '$2 > 10 {print $1}' | wc -l)
BENCHMARK_FILES=$(find tests -name "*benchmark*" -o -name "*perf*" 2>/dev/null | wc -l)
if [ "$LONG_FUNCTIONS" -gt 0 ] && [ "$BENCHMARK_FILES" -eq 0 ]; then
    print_warning "⚠️ PERFORMANCE RULE: Functions >10 lines should have performance benchmarks"
    print_status "💡 Create tests/benchmarks/ with pytest-benchmark tests"
fi

# 4. Pre-commit hooks (fast file-level checks)
print_status "📝 Running pre-commit hooks (auto-fixing issues)..."
# Run pre-commit hooks up to 3 times to handle auto-fixes
max_attempts=3
attempt=1
hooks_passed=false

while [ $attempt -le $max_attempts ]; do
    print_status "🔧 Pre-commit run attempt $attempt/$max_attempts..."

    if uv run pre-commit run --all-files; then
        hooks_passed=true
        print_success "✅ All pre-commit hooks passed!"
        break
    else
        if [ $attempt -lt $max_attempts ]; then
            print_warning "⚡ Pre-commit hooks auto-fixed issues, running again..."

            # Auto-stage any files that were modified by the hooks
            if ! git diff --quiet; then
                print_status "📝 Auto-staging fixed files for next attempt..."
                git add -A
                print_success "✅ Modified files staged for retry"
            fi

            # Give a moment for file system to sync
            sleep 1
        fi
    fi

    ((attempt++))
done

if [ "$hooks_passed" != "true" ]; then
    print_error "❌ Pre-commit hooks failed after $max_attempts attempts!"
    print_error "🚨 MASTER RULESET VIOLATION: Code quality standards not met"
    print_status "💡 Review the errors above and fix manually, then run:"
    print_status "   cd $(pwd) && pre-commit run --all-files"
    exit 1
fi

# Verify all changes have been staged after pre-commit hooks
if ! git diff --quiet; then
    print_status "📝 Staging any remaining auto-fixed changes..."
    git add -A
    print_success "✅ Final auto-fixes applied and staged"
fi

# 5. MANDATORY: Ruff ultra-fast linting
print_status "🚀 MASTER RULE: Ruff ultra-fast linting..."
if ! uv run ruff check src tests; then
    print_error "❌ MASTER RULE VIOLATION: Ruff linting failed"
    exit 1
fi

# Run ruff format and stage any additional changes
uv run ruff format src tests
if ! git diff --quiet; then
    print_status "📝 Auto-staging ruff format changes..."
    git add -A
    print_success "✅ Ruff formatting changes staged"
fi

# Now check that everything is properly formatted
if ! uv run ruff format --check src tests; then
    print_error "❌ MASTER RULE VIOLATION: Code formatting issues found"
    exit 1
fi
print_success "✅ Ruff linting and formatting verified"

# 6. MANDATORY: Security scanning
print_status "🛡️ MASTER RULE: Security vulnerability scanning..."
uv run bandit -r src -f json -o bandit-report.json >/dev/null 2>&1 || true
HIGH_ISSUES=$(cat bandit-report.json 2>/dev/null | jq -r '.results[] | select(.issue_severity == "HIGH") | .test_name' | wc -l || echo "0")
if [ "$HIGH_ISSUES" -gt 0 ]; then
    print_error "❌ MASTER RULE VIOLATION: $HIGH_ISSUES high-severity security issues found"
    print_error "🚨 SECURITY FIRST: Fix all high-severity issues before commit"
    exit 1
fi

# Run safety check on dependencies
if ! uv run safety check --json >/dev/null 2>&1; then
    print_warning "⚠️ SECURITY: Dependency vulnerabilities found (check with 'uv run safety check')"
fi

print_success "✅ Security scanning completed"

# 7. MANDATORY: Memory leak detection in tests
print_status "🧠 MASTER RULE: Memory leak detection..."
if [ -d "tests" ]; then
    # Skip benchmark tests during pre-commit (Wave 3 optimization)
    if ! uv run pytest tests/unit --maxfail=1 -q --tb=no -m "not benchmark" 2>/dev/null; then
        print_error "❌ MASTER RULE VIOLATION: Unit tests failed"
        print_status "💡 If benchmark plugin is missing, install with: uv add --dev pytest-benchmark"
        exit 1
    fi

    # Check for memory tests
    MEMORY_TESTS=$(find tests -name "*.py" -exec grep -l "tracemalloc\|memray\|memory" {} \; 2>/dev/null | wc -l)
    if [ "$MEMORY_TESTS" -eq 0 ]; then
        print_warning "⚠️ PERFORMANCE RULE: No memory tests found"
        print_status "💡 Add memory leak detection tests with tracemalloc"
    fi
fi

# 8. Documentation validation
print_status "📚 Documentation compliance check..."
if ! uv run pydocstyle src --count >/dev/null 2>&1; then
    print_warning "⚠️ Documentation style issues found (run 'uv run pydocstyle src' for details)"
fi

# 9. MANDATORY: Type coverage validation
print_status "🎯 MASTER RULE: Type coverage validation..."
TYPE_COVERAGE=$(uv run mypy --strict src 2>&1 | grep -o "Found [0-9]* error" | grep -o "[0-9]*" || echo "0")
if [ "$TYPE_COVERAGE" -gt 0 ]; then
    print_error "❌ MASTER RULE VIOLATION: $TYPE_COVERAGE type errors found"
    print_error "🚨 TYPE SAFETY: 100% type coverage required"
    exit 1
fi

# 10. MANDATORY: Result Type Usage Check
print_status "🔄 MASTER RULE: Result type usage validation..."
EXCEPTION_FLOW=$(find src -name "*.py" -exec grep -l "raise.*Exception\|except.*:" {} \; 2>/dev/null | wc -l)
RESULT_USAGE=$(find src -name "*.py" -exec grep -l "Result\[" {} \; 2>/dev/null | wc -l)
if [ "$EXCEPTION_FLOW" -gt 0 ] && [ "$RESULT_USAGE" -eq 0 ]; then
    print_warning "⚠️ DEFENSIVE PROGRAMMING: Consider using Result[T, E] types instead of exceptions for flow control"
fi

print_header "🎯 MASTER RULESET ENFORCEMENT SUMMARY"
print_success "✅ Pydantic Model Compliance: PASSED"
print_success "✅ Type Safety (MyPy Strict): PASSED"
print_success "✅ Performance Standards: VERIFIED"
print_success "✅ Security Scanning: PASSED"
print_success "✅ Memory Leak Detection: VERIFIED"
print_success "✅ Code Quality (Ruff): PASSED"
print_header "🚀 ALL MASTER RULESET REQUIREMENTS SATISFIED!"
print_status "💡 Build and comprehensive benchmarks will run in CI pipeline"
