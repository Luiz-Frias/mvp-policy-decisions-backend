[pytest]
# Pytest configuration for MVP Policy Decision Backend

# Test discovery patterns
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Test paths
testpaths = tests

# Markers for test categorization
markers =
    unit: Unit tests for individual components
    integration: Integration tests for API endpoints
    benchmark: Performance benchmark tests
    slow: Tests that take longer than 1 second
    asyncio: Asynchronous tests

# Asyncio configuration
asyncio_mode = auto

# Coverage configuration
addopts =
    --strict-markers
    --strict-config
    --verbose
    --tb=short
    --cov-branch
    --cov-report=term-missing:skip-covered
    --cov-fail-under=80

# Ignore warnings from dependencies
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::FutureWarning

# Timeout for tests (requires pytest-timeout plugin)
# timeout = 300

# Console output options
console_output_style = progress

# Logging configuration
log_cli = false
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Benchmark plugin settings
# NOTE: Benchmark configuration moved to pytest-benchmark.ini
# To run performance tests: pytest -c pytest-benchmark.ini -m benchmark
# This avoids config errors when pytest-benchmark isn't installed

# Doctest configuration
doctest_optionflags = NORMALIZE_WHITESPACE IGNORE_EXCEPTION_DETAIL

# Parallel execution (requires pytest-xdist)
# addopts = -n auto
