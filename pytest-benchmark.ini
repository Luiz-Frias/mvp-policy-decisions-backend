[pytest]
# Performance testing configuration for Wave 3 optimization
# Usage: pytest -c pytest-benchmark.ini -m benchmark

# Inherit all settings from main pytest.ini
# Test discovery patterns
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Test paths
testpaths = tests

# Markers for test categorization
markers =
    unit: Unit tests for individual components
    integration: Integration tests for API endpoints
    benchmark: Performance benchmark tests
    slow: Tests that take longer than 1 second
    asyncio: Asynchronous tests

# Asyncio configuration
asyncio_mode = auto

# Coverage configuration
addopts =
    --strict-markers
    --strict-config
    --verbose
    --tb=short

# Ignore warnings from dependencies
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::FutureWarning

# Timeout for tests (requires pytest-timeout plugin)
# timeout = 300

# Console output options
console_output_style = progress

# Logging configuration
log_cli = false
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# PERFORMANCE BENCHMARK SETTINGS
# These require pytest-benchmark to be installed
benchmark_only = false
benchmark_skip = false
benchmark_disable = false
benchmark_save = .benchmarks
benchmark_compare_fail = performance:5%
benchmark_min_rounds = 10
benchmark_max_time = 1.0
benchmark_min_time = 0.000005
benchmark_warmup = true

# Performance regression thresholds (Wave 3)
# Functions >10 lines must maintain <100ms response time
# Memory allocation <1MB per function
# No memory growth >1MB in 1000 iterations

# Doctest configuration
doctest_optionflags = NORMALIZE_WHITESPACE IGNORE_EXCEPTION_DETAIL
